import numpy as np
import torch
import helper_functions as hfuncs
import time
from matplotlib import pyplot as plt


def _plot(x_t_pairs_):
    plt.scatter(x_t_pairs_[:, 0], x_t_pairs_[:, 1])
    plt.title('polynomial + Gaussian noise for m=2')
    plt.gca().spines['top'].set_visible(False)
    plt.gca().spines['right'].set_visible(False)
    plt.xlabel('x')
    plt.ylabel('y')
    # plt.savefig('plots/observed.jpg')
    plt.show()


if __name__ == '__main__':

    w_true = np.array([[1], [2], [3]])
    w_true = hfuncs.convert_to_tensor(w_true)

    # # Generate training set:
    train_20_x = np.random.uniform(low=-20, high=20, size=20).reshape(-1, 1)
    train_20_x = hfuncs.convert_to_tensor(train_20_x)

    # # Generate test set:
    test_10_x = np.random.uniform(low=-20, high=20, size=10).reshape(-1, 1)
    test_10_x = hfuncs.convert_to_tensor(test_10_x)

    # # Generate observed ("target") values, using polynomial function and Gaussian noise:
    train_20_y = hfuncs.polynomial_fun(w_true, train_20_x)  # This is the "true" polynomial curve  (i.e. "ground-truth")
    train_20_t = torch.randn_like(train_20_y) * 0.5 + train_20_y  # Add Gaussian noise to simulate the observed data.

    test_10_y = hfuncs.polynomial_fun(w_true, test_10_x)  # This is the "true" polynomial curve (i.e. "ground-truth")
    test_10_t = torch.randn_like(test_10_y) * 0.5 + test_10_y  # Add Gaussian noise to simulate the observed data.

    # # Compute optimum weight vector:
    x_t_pairs = torch.cat((train_20_x, train_20_t), dim=1)

    x_t_pairs_test = torch.cat((test_10_x, test_10_t), dim=1)

    # _plot(x_t_pairs)

    for m in [2, 3, 4]:
        start = time.time()
        w_hat = hfuncs.fit_polynomial_ls(x_t_pairs=x_t_pairs, m=m)
        print(f'fit_polynomial_ls() took {round(time.time() - start, 4)} secs for m={m}')
        y_preds_train = hfuncs.polynomial_fun(w=w_hat, x=train_20_x)
        y_preds_test = hfuncs.polynomial_fun(w=w_hat, x=test_10_x)

        # # OBSERVED --------------------------------------------------------------------------------------------------

        # # a) Print mean & standard deviation in difference between the observed training data and the underlying
        # # “true” polynomial curve.
        # # I interpret the "observed" to mean the "target", and the "true" polynomial curve as that generated by
        # # polynomial_fun() with degree=2 and w=[1, 2, 3].
        diff_train = train_20_t - train_20_y
        mean_obs_train = round(float(diff_train.mean()), 4)
        std_obs_train = round(float(diff_train.std()), 4)
        print(f"For m={m}, (Training set) Mean and standard deviation in difference between the observed training"
              f"data and the underlying 'true' polynomial curve is {mean_obs_train} +/- {std_obs_train} to 4 sig. "
              f"figs.")
        diff_test = test_10_t - test_10_y
        mean_obs_test = round(float(diff_test.mean()), 4)
        std_obs_test = round(float(diff_test.std()), 4)
        print(f"For m={m}, (Test set) Mean and standard deviation in difference between the observed training data"
              f"and the underlying 'true' polynomial curve for the test set is "
              f"{mean_obs_test} +/- {std_obs_test} to 4 sig. figs.")

        # # LS-PREDICTED ----------------------------------------------------------------------------------------------

        # # b) Print mean & standard deviation in difference between the “LS-predicted” values and the underlying
        # # “true” polynomial curve.
        diff_ls_train = y_preds_train - train_20_y
        mean_ls_train = hfuncs.round_sig_figs(float(diff_ls_train.mean()), 4)
        std_ls_train = hfuncs.round_sig_figs(float(diff_ls_train.std()), 4)
        print(f"For m={m}, (Training set) Mean and standard deviation in difference between the 'LS-predicted'"
              f"values and the underlying 'true' polynomial curve is {mean_ls_train} +/- {std_ls_train} to 4 sig. "
              f"figs.")

        diff_ls_test = y_preds_test - test_10_y
        mean_ls_test = hfuncs.round_sig_figs(float(diff_ls_test.mean()), 4)
        std_ls_test = hfuncs.round_sig_figs(float(diff_ls_test.std()), 4)
        print(f"For m={m}, (Test set) Mean and standard deviation in difference between the 'LS-predicted' values"
              f"and the underlying 'true' polynomial curve is {mean_ls_test} +/- {std_ls_test} to 4 sig. figs.")

        # # SGD-PREDICTED ---------------------------------------------------------------------------------------------

        start = time.time()
        w_hat = hfuncs.fit_polynomial_sgd(x_t_pairs=x_t_pairs, m=m)
        print(f'fit_polynomial_sgd() took {hfuncs.round_sig_figs(x=time.time() - start, sf=4)} secs for m={m}')

        # # For a more informative method, uncomment and run the following function which is identical to
        # # fit_polynomial_sgd, but includes LEARNING CURVES of the BOTH TRAINING AND TEST sets together:
        # w_hat = hfuncs.fit_polynomial_sgd_and_test(x_t_test_set_pairs=x_t_pairs_test, x_t_pairs=x_t_pairs, m=m)

        # # Print mean & standard deviation in difference between the “SGD-predicted” values and the underlying “true”
        # # polynomial curve.
        y_preds_train = hfuncs.polynomial_fun(w=w_hat, x=train_20_x)
        y_preds_test = hfuncs.polynomial_fun(w=w_hat, x=test_10_x)

        diff_ls_train = y_preds_train - train_20_y
        mean_ls_train = hfuncs.round_sig_figs(float(diff_ls_train.mean()), 4)
        std_ls_train = hfuncs.round_sig_figs(float(diff_ls_train.std()), 4)
        print(f"For m={m}, (Training set) Mean and standard deviation in difference between the 'SGD-predicted'"
              f"values and the underlying 'true' polynomial curve is {mean_ls_train} +/- {std_ls_train} to 4 sig."
              f"figs.")

        diff_ls_test = y_preds_test - test_10_y
        mean_ls_test = hfuncs.round_sig_figs(float(diff_ls_test.mean()), 4)
        std_ls_test = hfuncs.round_sig_figs(float(diff_ls_test.std()), 4)
        print(f"For m={m}, (Test set) Mean and standard deviation in difference between the 'SGD-predicted' values"
              f"and the underlying 'true' polynomial curve is {mean_ls_test} +/- {std_ls_test}")
        print(w_hat)

